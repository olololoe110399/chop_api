import os

import streamlit as st

from init.llm2 import Recommender
# from langchain.embeddings.openai import OpenAIEmbeddings
# from langchain.vectorstores import FAISS
from init.similarity_search import SimilaritySearch

st.header(":rocket: Tr√≤ chuy·ªán v·ªõi ChopAI :page_facing_up:")

st.sidebar.info("Vui l√≤ng reload l·∫°i trang sau khi c√†i ƒë·∫∑t c·ªßa kh√°ch h√†ng.", icon="üö®")

try:

    if "vectorstore" not in st.session_state:
        with st.spinner('ƒêang t·∫£i d·ªØ li·ªáu...'):
            # if not os.path.exists(os.path.join(os.getcwd(), 'resources/vectordb')):
            if not os.path.exists(os.path.join(os.getcwd(), 'resources/processed_data_with_embeddings.json')):
                st.info("Vui l√≤ng t·∫°o chatbot tr∆∞·ªõc khi s·ª≠ d·ª•ng.", icon="üö®")
                st.stop()
            vectorstore = SimilaritySearch(os.path.join(os.getcwd(), 'resources/processed_data_with_embeddings.json'))
            # vectorstore = FAISS.load_local(os.path.join(os.getcwd(), 'resources/vectordb'), OpenAIEmbeddings())
            st.session_state['vectorstore'] = vectorstore

    if "vectorstore" in st.session_state:
        vectorstore = st.session_state['vectorstore']

        if "messages" not in st.session_state:
            with open(os.path.join(os.getcwd(), "resources/system_message"), "r") as file:
                system_message = file.read()
            st.session_state.messages = [{
                "role": "system",
                "content": system_message
            }]
            recommender = Recommender()
            st.session_state['recommender'] = recommender

        for message in st.session_state.messages:
            if message["role"] != "system":
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

        if prompt := st.chat_input("Ask your questions?"):
            recommender = st.session_state['recommender']
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                with st.spinner('ƒêang suy nghƒ©  ...'):
                    recommender_response = recommender.recommend(
                        "user",
                        f"""T∆∞ v·∫•n v√† chƒÉm s√≥c kh√°ch h√†ng  ƒë√¢y l√† c√¢u h·ªèi c·ªßa KH h√†ng: {prompt}"""
                    )
                if 'search term for retrieval' not in recommender_response:
                    st.session_state.messages.append(
                        {"role": "assistant",
                         "content": recommender_response['your response to user']}
                    )
                    st.markdown(recommender_response['your response to user'])
                    st.stop()
                if len(recommender_response['search term for retrieval']) == 0:
                    st.session_state.messages.append(
                        {"role": "assistant",
                         "content": recommender_response['your response to user']}
                    )
                    st.markdown(recommender_response['your response to user'])
                    st.stop()
                results = vectorstore.similarity_search(
                    recommender_response['search term for retrieval'][:3],
                )

                if len(results) == 0:
                    st.session_state.messages.append(
                        {"role": "assistant",
                         "content": recommender_response['your response to user']}
                    )
                    st.markdown(recommender_response['your response to user'])
                    st.stop()
                retrievals = []
                for result in results[:3]:
                    for record in result.head(3).to_dict('records'):
                        record.pop('embeddings', None)
                        record.pop('similarities', None)
                        retrievals.append(record)

                if len(retrievals) == 0:
                    st.session_state.messages.append(
                        {
                            "role": "assistant",
                            "content": recommender_response['your response to user']
                        }
                    )
                    st.markdown(recommender_response['your response to user'])
                    st.stop()
                print("retrievals", retrievals)
                with st.spinner('ƒêang g·ª£i √Ω  ...'):
                    final_result = recommender.recommend(
                        "assistant",
                        f"ƒê√¢y l√† c√°c s·∫£n ph·∫©m ph√π h·ª£p v·ªõi ng∆∞·ªùi d√πng: \n\n {str(retrievals)}"
                        f"H√£y ghi nh·ªõ nh·ªØng ƒë·ªÅ xu·∫•t n√†y trong su·ªët cu·ªôc tr√≤ chuy·ªán "
                        f"c·ªßa b·∫°n v·ªõi ng∆∞·ªùi d√πng v√† b√¢y gi·ªù h√£y tr·∫£ l·ªùi cho ng∆∞·ªùi d√πng th√¥ng tin c·ªßa s·∫£n ph·∫©m n√†y "
                        f"v√† nh·ªõ t∆∞ v·∫•n v√¨ sao n√™n d√πng nh·ªØng s·∫£n ph·∫©m n√†y."
                        f"(Lu√¥n lu√¥n ƒë√≠nh k√®m url, image_url, name, price m·ªôt c√°ch ƒë·∫πp m·∫Øt b·∫±ng markdown n·∫øu c√≥)"
                        f"L∆ØU √ù: Kh√¥ng ƒë∆∞·ª£c t·ª± t·∫°o s·∫£n ph·∫©m gi·∫£, ch·ªâ tr·∫£ v·ªÅ c√°c s·∫£n ph·∫©m t·ª´ ph√π h·ª£p ·ªü tr√™n"
                    )
                    st.markdown(final_result['your response to user'])
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": final_result['your response to user']
                    })
except Exception as e:
    st.error(e)
    st.error("C√≥ l·ªói x·∫£y ra, vui l√≤ng th·ª≠ l·∫°i.")
